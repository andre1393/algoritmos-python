{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from clean_text import TextCleaner\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! pip install spacy\n",
    "#! python -m spacy download pt_core_news_sm\n",
    "#! python -m spacy download en\n",
    "nltk.download('punkt', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementação do Bayesian Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(X, x, c = 2):\n",
    "    m = X.mean(0)\n",
    "    N = x.shape[0]\n",
    "    alfa = c * m\n",
    "    beta = c * (1 - m)\n",
    "    alfa_ = alfa + x.sum(0)\n",
    "    beta_ = beta + N - x.sum(0)\n",
    "    nc = (np.log(alfa + beta) - np.log(alfa + beta + N) + np.log(beta_) - np.log(beta)).sum(1)\n",
    "    q = np.log(alfa_) - np.log(alfa) + np.log(beta) - np.log(beta_)\n",
    "    s = nc + (X * q.T)\n",
    "    \n",
    "    return s\n",
    "\n",
    "def search(query, corpus, clean_text = True):    \n",
    "    # clean text\n",
    "    if clean_text:\n",
    "        cleaner = TextCleaner(clean_regex = \".*\")\n",
    "        query = cleaner.clean(query)\n",
    "        corpus = cleaner.clean(corpus)\n",
    "    \n",
    "    # create DTM\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    DTM = vec.transform(corpus)\n",
    "    DTM_query = vec.transform(query)\n",
    "    \n",
    "    # calculate scores\n",
    "    s = score(DTM, DTM_query)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Utilizando o algoritmo e fazendo limpeza no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = '~/github/data/datasets/movies.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Little Mermaid, The</td>\n",
       "      <td>10.091983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23240</th>\n",
       "      <td>Beauty and the Beast</td>\n",
       "      <td>9.963770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Beauty and the Beast</td>\n",
       "      <td>9.963770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23241</th>\n",
       "      <td>Beauty and the Beast (Beauty and the Beasts: A...</td>\n",
       "      <td>9.944825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Lion King, The</td>\n",
       "      <td>9.696858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>9.044807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>Toy Story 2</td>\n",
       "      <td>9.044807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15401</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>9.044807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7960</th>\n",
       "      <td>Cinderella Story, A</td>\n",
       "      <td>9.044807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9398</th>\n",
       "      <td>Lion King 1½, The</td>\n",
       "      <td>8.192724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18252</th>\n",
       "      <td>Another Cinderella Story</td>\n",
       "      <td>7.539673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21981</th>\n",
       "      <td>Toy Story of Terror</td>\n",
       "      <td>7.539502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19335</th>\n",
       "      <td>Little Mermaid: Ariel's Beginning, The</td>\n",
       "      <td>7.083172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12874</th>\n",
       "      <td>Little Mermaid 2: Return to the Sea, The</td>\n",
       "      <td>7.079544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>Rusalochka (The Little Mermaid)</td>\n",
       "      <td>7.078531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>Beast of War, The (Beast, The)</td>\n",
       "      <td>7.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19146</th>\n",
       "      <td>Beauty and the Beast: The Enchanted Christmas</td>\n",
       "      <td>6.952243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26654</th>\n",
       "      <td>Hercules</td>\n",
       "      <td>6.649708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>Hercules</td>\n",
       "      <td>6.649708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23754</th>\n",
       "      <td>Hercules</td>\n",
       "      <td>6.649708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23511</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>6.408683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23520</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>6.408683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>Toy, The</td>\n",
       "      <td>6.408683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>6.408683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27069</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>6.408683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13118</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>6.408683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Ever After: A Cinderella Story</td>\n",
       "      <td>6.035825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25102</th>\n",
       "      <td>A Cinderella Story: Once Upon a Song</td>\n",
       "      <td>6.034626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25463</th>\n",
       "      <td>Toy Story That Time Forgot</td>\n",
       "      <td>6.031615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15681</th>\n",
       "      <td>Beast, The</td>\n",
       "      <td>5.465226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title      value\n",
       "1997                                Little Mermaid, The   10.091983\n",
       "23240                              Beauty and the Beast    9.963770\n",
       "589                                Beauty and the Beast    9.963770\n",
       "23241  Beauty and the Beast (Beauty and the Beasts: A...   9.944825\n",
       "360                                      Lion King, The    9.696858\n",
       "0                                             Toy Story    9.044807\n",
       "3027                                        Toy Story 2    9.044807\n",
       "15401                                       Toy Story 3    9.044807\n",
       "7960                                Cinderella Story, A    9.044807\n",
       "9398                                  Lion King 1½, The    8.192724\n",
       "18252                          Another Cinderella Story    7.539673\n",
       "21981                               Toy Story of Terror    7.539502\n",
       "19335            Little Mermaid: Ariel's Beginning, The    7.083172\n",
       "12874          Little Mermaid 2: Return to the Sea, The    7.079544\n",
       "18646                   Rusalochka (The Little Mermaid)    7.078531\n",
       "4380                     Beast of War, The (Beast, The)    7.000921\n",
       "19146     Beauty and the Beast: The Enchanted Christmas    6.952243\n",
       "26654                                          Hercules    6.649708\n",
       "1515                                           Hercules    6.649708\n",
       "23754                                          Hercules    6.649708\n",
       "23511                                        Cinderella    6.408683\n",
       "23520                                        Cinderella    6.408683\n",
       "4833                                           Toy, The    6.408683\n",
       "1003                                         Cinderella    6.408683\n",
       "27069                                        Cinderella    6.408683\n",
       "13118                                        Cinderella    6.408683\n",
       "2041                     Ever After: A Cinderella Story    6.035825\n",
       "25102              A Cinderella Story: Once Upon a Song    6.034626\n",
       "25463                        Toy Story That Time Forgot    6.031615\n",
       "15681                                        Beast, The    5.465226"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(movies)\n",
    "\n",
    "# remove release year from movie title\n",
    "df['title'] = df['title'].apply(lambda x: re.sub(\"\\\\([0-9]+\\\\)\", \"\", x))\n",
    "\n",
    "s = search(['toy story', 'the lion king','alladin','beauty and the beast','cinderella','little mermaid','hercules'] , df['title'])\n",
    "\n",
    "data = {'title': df['title'], 'value': np.asarray(s).tolist()}\n",
    "df = pd.DataFrame(data)\n",
    "df['value'] = df['value'].apply(lambda x: x[0])\n",
    "df.sort_values('value', ascending = False).iloc[0:30, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Crie um classificador utilizando word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_review = '~/github/data/datasets/movie_review.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(movie_review)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    # remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    \n",
    "    # convert to lower case and split at whitespace\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return words\n",
    "\n",
    "def review_to_sentences(review, tokenizer, remove_stopwords=True):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []    \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [review_to_sentences(review, tokenizer, remove_stopwords = True)[0] for review in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for various word2vec parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 4   # Minimum word count                        \n",
    "num_workers = 3       # Number of threads to run in parallel\n",
    "context = 3           # Context window size\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count = min_word_count,\n",
    "    window = context, \n",
    "    sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(words, model, num_features):\n",
    "    feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index2word)  # words known to the model\n",
    "\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vec = np.add(feature_vec,model[word])\n",
    "    \n",
    "    feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "def get_avg_feature_vecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    review_feature_vecs = np.zeros((len(reviews),num_features), dtype='float32')  # pre-initialize (for speed)\n",
    "    \n",
    "    for review in reviews:\n",
    "        review_feature_vecs[counter,:] = make_feature_vec(review, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return review_feature_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "clean_reviews = []\n",
    "for review in df['text']:\n",
    "    clean_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "trainDataVecs = get_avg_feature_vecs(clean_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo linhas com valores nan\n",
    "not_null = ~np.isnan(trainDataVecs).any(axis=1)\n",
    "X = trainDataVecs[not_null]\n",
    "y = df['tag'][not_null]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to fit: 204.60\n",
      "time to predict: 1.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "model = RandomForestClassifier(n_estimators= 100)\n",
    "t0 = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"time to fit: %.2f\" % (t1 - t0))\n",
    "y_pred = model.predict(X_test)\n",
    "t2 = time.time()\n",
    "print(\"time to predict: %.2f\" % (t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4853, 4562],\n",
       "       [4181, 5663]], dtype=int64)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.54      0.52      0.53      9415\n",
      "         pos       0.55      0.58      0.56      9844\n",
      "\n",
      "   micro avg       0.55      0.55      0.55     19259\n",
      "   macro avg       0.55      0.55      0.55     19259\n",
      "weighted avg       0.55      0.55      0.55     19259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
